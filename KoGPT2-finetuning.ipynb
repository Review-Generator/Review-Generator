{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22805,"status":"ok","timestamp":1640674794205,"user":{"displayName":"박규현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12057282766822864307"},"user_tz":-540},"id":"sRcT-JoST_SC","outputId":"dfa2a5d6-26f5-4693-9d06-2ba1e6fcfeb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1640674794207,"user":{"displayName":"박규현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12057282766822864307"},"user_tz":-540},"id":"6z_UF32XOTL9","outputId":"27200c32-9505-4935-df3c-01841263dec7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/KoGPT2-finetuning-master\n"]}],"source":["cd /content/drive/MyDrive/KoGPT2-finetuning-master"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124284,"status":"ok","timestamp":1640674918484,"user":{"displayName":"박규현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12057282766822864307"},"user_tz":-540},"id":"p68_yrjTOaFU","outputId":"6278a20d-dcbb-43a0-fd36-f681d21bfa51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mxnet==1.6.0\n","  Downloading mxnet-1.6.0-py2.py3-none-any.whl (68.7 MB)\n","\u001b[K     |████████████████████████████████| 68.7 MB 119 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.62.3)\n","Collecting gluonnlp==0.8.3\n","  Downloading gluonnlp-0.8.3.tar.gz (236 kB)\n","\u001b[K     |████████████████████████████████| 236 kB 72.8 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.6\n","  Downloading sentencepiece-0.1.6-cp37-cp37m-manylinux1_x86_64.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 51.5 MB/s \n","\u001b[?25hCollecting torch==1.5.1\n","  Downloading torch-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (753.2 MB)\n","\u001b[K     |████████████████████████████████| 753.2 MB 14 kB/s \n","\u001b[?25hCollecting transformers==4.1.1\n","  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 72.4 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 74.8 MB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1->-r requirements.txt (line 5)) (0.16.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 6)) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 70.6 MB/s \n","\u001b[?25hCollecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 6)) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 6)) (3.4.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 7)) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 7)) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1->-r requirements.txt (line 6)) (3.0.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1->-r requirements.txt (line 6)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1->-r requirements.txt (line 6)) (1.1.0)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.8.3-py3-none-any.whl size=293555 sha256=7caeedbea5e22f0f3c53db20e248f20a77d366bb5af4fa449efdfbabb8df63b2\n","  Stored in directory: /root/.cache/pip/wheels/1d/11/a7/dbd80409d49af1066d14419f604dd823ab24cb4ebecde8db6e\n","Successfully built gluonnlp\n","Installing collected packages: tokenizers, sacremoses, graphviz, transformers, torch, tensorboardX, sentencepiece, mxnet, gluonnlp\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.5.1 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.1 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.1 which is incompatible.\u001b[0m\n","Successfully installed gluonnlp-0.8.3 graphviz-0.8.4 mxnet-1.6.0 sacremoses-0.0.46 sentencepiece-0.1.6 tensorboardX-2.4.1 tokenizers-0.9.4 torch-1.5.1 transformers-4.1.1\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3278,"status":"ok","timestamp":1640674921753,"user":{"displayName":"박규현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12057282766822864307"},"user_tz":-540},"id":"FF9oTrwuOcRS","outputId":"039b9209-3fb9-477e-ea4e-749518f3a838"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers==4.1.1 in /usr/local/lib/python3.7/dist-packages (4.1.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.0.46)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.9.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (7.1.2)\n"]}],"source":["!pip install transformers==4.1.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362847,"status":"ok","timestamp":1640168745729,"user":{"displayName":"박규현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12057282766822864307"},"user_tz":-540},"id":"0MaX4GJkOhyJ","outputId":"ffe17cd5-bdcd-4d26-f0d8-192503d5ea86"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n","  Optimizer.opt_registry[name].__name__))\n","using cached model\n","0\n","using cached model\n","data read: --------OK-------\n","tokenizer ending\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","(4070, 3)\n","Read_Dataset ok\n","KoGPT-2 Transfer Learning Start\n","epoch no.0 train no.0  loss = 14.84440 avg_loss = 14.84440\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","epoch no.0 train no.10  loss = 10.07295 avg_loss = 11.32351\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","epoch no.0 train no.20  loss = 9.41263 avg_loss = 10.51016\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","epoch no.0 train no.30  loss = 8.71976 avg_loss = 10.00709\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","epoch no.0 train no.40  loss = 7.98409 avg_loss = 9.50128\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","epoch no.0 train no.50  loss = 7.75953 avg_loss = 9.10492\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","epoch no.0 train no.60  loss = 7.19386 avg_loss = 8.76064\n","61\n","62\n","63\n","101\n","to_tokens: ['▁사이즈', '도', '▁넉넉', '하고', '▁넉넉', '▁입', '하고', '▁넉넉', '하고', '요', '▁넉넉', '하고', '▁넉넉', '▁넉넉', '하고', '▁넉넉', '요', '요', '▁입', '▁입', '▁입', '하고', '도', '▁넉넉', '요', '요', '요', '▁입', '요', '하고', '요', '요', '▁입', '요', '▁입', '요', '▁입', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요', '요']\n","사이즈도 넉넉하니 입 예뻐하고 넉넉요 커서 넉넉하니도 넉넉해서 예뻐하고 입 너무 입를 사이즈도 넉넉하고 좀요요 넉넉하고요 입요 입요 입요하고요요요해서 넉넉요 입요요요요요요요 입요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요요\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","epoch no.1 train no.70  loss = 6.78725 avg_loss = 8.40190\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","epoch no.1 train no.80  loss = 6.80587 avg_loss = 8.10823\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","epoch no.1 train no.90  loss = 6.49549 avg_loss = 7.83091\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","epoch no.1 train no.100  loss = 6.25435 avg_loss = 7.58482\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","epoch no.1 train no.110  loss = 5.85106 avg_loss = 7.38094\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","epoch no.1 train no.120  loss = 6.20822 avg_loss = 7.18601\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","32\n","to_tokens: ['▁사이즈', '도', '▁넉넉', '하니', '▁넉넉', '하고', '▁넉넉', '하고', '▁옷', '낙', '하니', '하니', '하고', '고', '</s>', '핑', '</s>', '▁커서', '▁이거', '고', '요', '▁적당', '하고', '해서', '하고', '고', '고', '▁커서', '▁커서', '▁커서', '▁커서', '▁커서', '▁커서']\n","사이즈도 넉넉하고 넉넉하고랑하고 낙낙하니 이거고해서 핫핑낙하니 이거고는도 넉넉해서요 커서 커서 커서 커서 커서 커서 커서 커서</s>\n","128\n","129\n","130\n","epoch no.2 train no.130  loss = 5.94896 avg_loss = 7.00931\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","epoch no.2 train no.140  loss = 5.70475 avg_loss = 6.83268\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","epoch no.2 train no.150  loss = 5.52972 avg_loss = 6.68877\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","epoch no.2 train no.160  loss = 6.03461 avg_loss = 6.54579\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","epoch no.2 train no.170  loss = 5.21504 avg_loss = 6.42161\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","epoch no.2 train no.180  loss = 5.69208 avg_loss = 6.31569\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","epoch no.2 train no.190  loss = 5.30827 avg_loss = 6.20261\n","191\n","12\n","to_tokens: ['▁사이즈', '도', '▁넉넉', '하고', '▁사이즈', '커', '요', '</s>', '도', '▁넉넉', '하고', '</s>', '</s>', '</s>']\n","사이즈도 적당하고 너무 커요 사이즈도 넉넉해서하고 잘</s>\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","epoch no.3 train no.200  loss = 5.40320 avg_loss = 6.09259\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","epoch no.3 train no.210  loss = 4.94705 avg_loss = 5.96767\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","epoch no.3 train no.220  loss = 5.45106 avg_loss = 5.88379\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","epoch no.3 train no.230  loss = 5.05356 avg_loss = 5.80159\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","epoch no.3 train no.240  loss = 4.88059 avg_loss = 5.72511\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","epoch no.3 train no.250  loss = 4.88607 avg_loss = 5.65135\n","251\n","252\n","253\n","254\n","255\n","12\n","to_tokens: ['▁사이즈', '도', '▁넉넉', '하고', '▁넉넉', '사이즈', '로', '▁넉넉', '하고', '▁핏', '도', '▁넉넉', '하고', '</s>']\n","사이즈도 넉넉하니 1사이즈도 넉넉하고 사이즈도 넉넉하고</s>\n","256\n","257\n","258\n","259\n","260\n","epoch no.4 train no.260  loss = 4.54972 avg_loss = 5.57655\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","epoch no.4 train no.270  loss = 4.74274 avg_loss = 5.48880\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","epoch no.4 train no.280  loss = 4.90956 avg_loss = 5.41579\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","epoch no.4 train no.290  loss = 4.53147 avg_loss = 5.34661\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","epoch no.4 train no.300  loss = 4.57528 avg_loss = 5.28109\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","epoch no.4 train no.310  loss = 4.62951 avg_loss = 5.23153\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","2\n","to_tokens: ['▁사이즈', '도', '▁잘', '▁적당']\n","사이즈도 딱</s>\n","320\n","epoch no.5 train no.320  loss = 4.16435 avg_loss = 5.16690\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","epoch no.5 train no.330  loss = 4.21215 avg_loss = 5.07641\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","epoch no.5 train no.340  loss = 4.43227 avg_loss = 5.00100\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","epoch no.5 train no.350  loss = 4.21929 avg_loss = 4.94180\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","epoch no.5 train no.360  loss = 4.09129 avg_loss = 4.88769\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","epoch no.5 train no.370  loss = 4.18470 avg_loss = 4.84445\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","epoch no.5 train no.380  loss = 4.75159 avg_loss = 4.80138\n","381\n","382\n","383\n","9\n","to_tokens: ['▁사이즈', '도', '▁잘', '▁맞고', '▁맘', '도', '▁잘', '▁크', '긴', '고']\n","사이즈도 잘 맞고 색깔도 약간  크긴</s>\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","epoch no.6 train no.390  loss = 4.23835 avg_loss = 4.74950\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","epoch no.6 train no.400  loss = 4.22532 avg_loss = 4.68346\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","epoch no.6 train no.410  loss = 3.81717 avg_loss = 4.63156\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","epoch no.6 train no.420  loss = 4.01165 avg_loss = 4.59708\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","epoch no.6 train no.430  loss = 4.11854 avg_loss = 4.54589\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","epoch no.6 train no.440  loss = 3.87275 avg_loss = 4.50040\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","4\n","to_tokens: ['▁사이즈', '도', '▁넉넉', '하고', '▁너무', '</s>']\n","사이즈도 넉넉하고 길이</s>\n","448\n","449\n","450\n","epoch no.7 train no.450  loss = 3.68075 avg_loss = 4.45151\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","epoch no.7 train no.460  loss = 3.77330 avg_loss = 4.38915\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","epoch no.7 train no.470  loss = 3.96031 avg_loss = 4.33113\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","epoch no.7 train no.480  loss = 3.62151 avg_loss = 4.29362\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","epoch no.7 train no.490  loss = 3.79531 avg_loss = 4.25319\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","epoch no.7 train no.500  loss = 3.80460 avg_loss = 4.22000\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","epoch no.7 train no.510  loss = 3.87582 avg_loss = 4.19117\n","511\n","5\n","to_tokens: ['▁사이', '도', '▁잘', '하고', '▁편', '하고', '</s>']\n","사이즈도 넉넉하고 편해요</s>\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","epoch no.8 train no.520  loss = 3.34162 avg_loss = 4.14042\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","epoch no.8 train no.530  loss = 3.84312 avg_loss = 4.08722\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","epoch no.8 train no.540  loss = 3.94574 avg_loss = 4.04085\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","epoch no.8 train no.550  loss = 3.84368 avg_loss = 4.01456\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","epoch no.8 train no.560  loss = 3.81142 avg_loss = 3.98195\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","epoch no.8 train no.570  loss = 3.78222 avg_loss = 3.95623\n","571\n","572\n","573\n","574\n","575\n","4\n","to_tokens: ['▁사이즈', '도', '▁넉넉', '이고', '▁넉넉', '</s>']\n","사이즈도 딱 맞고 좋아요</s>\n","576\n","577\n","578\n","579\n","580\n","epoch no.9 train no.580  loss = 3.43023 avg_loss = 3.92038\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","epoch no.9 train no.590  loss = 3.25627 avg_loss = 3.88479\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","epoch no.9 train no.600  loss = 3.12705 avg_loss = 3.85879\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","epoch no.9 train no.610  loss = 3.18587 avg_loss = 3.81665\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","epoch no.9 train no.620  loss = 3.52944 avg_loss = 3.77707\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","epoch no.9 train no.630  loss = 3.46804 avg_loss = 3.76290\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","4\n","to_tokens: ['▁사이즈', '도', '▁잘', '하고', '▁편', '</s>']\n","사이즈도 넉넉하고 좋아</s>\n","640\n"]}],"source":["!python main.py --epoch=10 --data_file_path=\"/content/drive/MyDrive/KoGPT2-finetuning-master/size_hotpink.csv\" --load_path=\"\" --batch_size=64"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wqe1fjz9QaFd","executionInfo":{"status":"ok","timestamp":1640689667191,"user_tz":-540,"elapsed":5410785,"user":{"displayName":"박규현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12057282766822864307"}},"outputId":"0d9d6cb6-7cd9-428d-aee4-ea0f7561f58e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n","  Optimizer.opt_registry[name].__name__))\n","[██████████████████████████████████████████████████]\n","using cached model\n","1001\n","to_tokens: ['▁배송', '상품은', '배송', '도', '▁다른', '▁제품이', '▁지연', '되는', '▁바람에', '▁좀', '▁배송', '이', '▁늦어', '졌는데', ',', '▁받고', '나', '니', '▁배송', '▁지연', '은', '▁더', '▁기다릴', '▁수', '▁있을', '▁거', '▁같은', '▁기분', '입니다', '▁']\n","작음배송한 다른 제품이 지연되는 바람에 좀 배송이 늦어졌는데, 받고나니 배송 지연은 더 기다릴 수 있을 거 같은 기분입니다\n","input :늦어\n","어\n","10\n","to_tokens: ['▁배송', '▁입', '으려고', '▁했던', '▁날', '▁입', '질', '▁못', '했', '네요', '.', '</s>']\n","늦어 입으려고 했던 날 입질 못했네요.</s>\n","input :느려\n","려\n","1001\n","to_tokens: ['▁배송', '월', '29', '일에', '▁주문', '했는데', '▁입', '고가', '안', '돼서', '▁배송', '이', '▁늦', '었지만', '▁구매', '하기', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘', '잘']\n","어월29일에 주문했는데 입고가안돼서 배송이 늦었지만 구매잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘잘\n","input :33\n","to_tokens: ['▁배송', '..', '▁구', '질의', '▁옷을', '▁별로', '▁안', '좋', '아', '하는', '▁것도', '▁있지만', ',', '▁관리', '도', '▁힘든', '▁린', '넨', '인데', '▁구', '겨진', '▁채로', '▁배송', '오', '니', '▁새', '▁옷', '인데도', '▁좀', '▁볼', '품', '없어', '▁보이', '네요', '</s>']\n","느려넨 재질의 옷을 별로 안좋아하는 것도 있지만, 관리도 힘든 린넨인데 구겨진 채로 배송오니 새 옷인데도 좀 볼품없어 보이네요</s>\n","input :6\n","to_tokens: ['▁배송', '져', '다가', '도', '▁빠르고', '랐', '어요', '~', '</s>']\n","려 배송도 빨랐어요~</s>\n","input :\n"]}],"source":["!python generator.py --temperature=1.0 --text_size=1000 --load_path=\"/content/drive/MyDrive/KoGPT2-finetuning-master/checkpoint/KoGPT2_checkpoint_11000.tar\" --tmp_sent=\"작음\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJxILjqATgL1"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"KoGPT2-finetuning(최종).ipynb","provenance":[],"authorship_tag":"ABX9TyNVwYDWEm/yH8IiEcI127Tm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}